# ELEC5305 Speech Dereverberation Project

Single-channel speech dereverberation with real room impulse responses (RIRs) for ELEC5305.  
This repository compares **classical frequency-domain baselines** with a lightweight Tiny-UNet model in terms of:

- Speech intelligibility (STOI)  
- Signal fidelity (SI-SDR)  
- Computational complexity / model size  

The code is designed to be **simple, reproducible and self-contained** for course use.

---

## 1. Project overview

- Task: Recover more intelligible speech from signals heavily reverberated by real RIRs.  
- Setup: Single-channel, synthetic reverberation generated by convolving clean speech with measured RIRs.  
- Key idea:  
  - Build a **room-aware, non-leaky** train/valid/test split (no RIR overlap between splits).  
  - Use spectral subtraction and Wiener filtering as classical baselines.  
  - Train a tiny U-Net on STFT magnitudes to estimate a real-valued mask.  
  - Evaluate all methods with **SI-SDR** and **STOI**.

This project is not intended to be state-of-the-art; it is a controlled study of how far a small neural model can go compared to simple DSP baselines under strong reverberation.

---

## 2. Methods

### 2.1 Data and RIRs

- Clean speech audio is stored under `dataset/clean/`.  
- Real room impulse responses (RIRs) from the **OpenSLR 28** database are stored under `rir/`.  
- Reverberant speech is generated by **frequency-domain convolution** of clean speech with RIRs.  
- A manifest file records, for each utterance:
  - `utt_id`
  - `clean_path`
  - `rev_path`
  - `rir_id`
  - `split` ∈ {`train`, `valid`, `test`}

Splits are defined per RIR, so that rooms in `test` are never seen during training.

### 2.2 Classical baselines

All classical methods operate on a **unified STFT front-end**:

- Sample rate: 16 kHz  
- FFT size: 512  
- Window length: 512 (Hann)  
- Hop size: 128  
- Implemented via `scipy.signal.stft/istft`

On top of this, two baselines are implemented:

- Spectral Subtraction (SS) 
  - Estimate a noise / reverberation floor from early frames.  
  - Apply over-subtraction and a spectral floor.  
  - Keep the original phase and reconstruct via ISTFT.

- Wiener Filtering
  - Estimate speech and noise power spectra with simple exponential smoothing.  
  - Apply the MMSE Wiener gain and reconstruct via ISTFT.

These methods are computationally cheap and require no training, but assume additive, quasi-stationary noise; they serve as a reference lower bound under strong reverberation.

### 2.3 Tiny-UNet model

Tiny-UNet is a small U-Net–style mask estimator operating on STFT magnitudes:

Architecture

- Encoder:
  - ConvBlock(1 → 16) + MaxPool2d(2)
  - ConvBlock(16 → 32) + MaxPool2d(2)
- Bottleneck:
  - ConvBlock(32 → 64)
- Decoder:
  - Up-sample 64 → 32, concat with encoder-2, ConvBlock(64 → 32)
  - Up-sample 32 → 16, concat with encoder-1, ConvBlock(32 → 16)
- Output:
  - 1×1 Conv: 16 → 1
  - Sigmoid to produce the mask

This design keeps the model very small while still enjoying U-Net’s skip-connections.

---

## 3. Metrics

Two objective metrics are used:

- SI-SDR (Scale-Invariant Signal-to-Distortion Ratio)  
  - Implemented explicitly in `utils/metrics.py`.  
  - Measures signal fidelity after projection onto the clean reference.  
- STOI (Short-Time Objective Intelligibility)  
  - Implemented via `pystoi`.  
  - Correlates with human intelligibility; scores range from 0 to 1.

All methods are evaluated on **exactly the same clean/enhanced pairs**, and we report:

- Global averages over all utterances  
- Averages per split (`train`, `valid`, `test`)

---

## 4. Repository structure
.
├─ dataset/
│  ├─ clean/           # clean speech (input)
│  └─ reverb/          # reverberant speech (generated)
├─ rir/                # selected real RIRs
├─ baselines/
│  ├─ ss/              # spectral subtraction outputs
│  ├─ wiener/          # Wiener filtering outputs
│  └─ tiny_unet/       # Tiny-UNet outputs (test set)
├─ models/
│  └─ tiny_unet.py     # Tiny-UNet implementation
├─ scripts/
│  ├─ generate_reverb.py
│  ├─ run_baselines.py
│  ├─ train_tiny_unet.py
│  ├─ run_tiny_unet.py
│  ├─ evaluate_methods.py
│  └─ export_demos.py
├─ utils/
│  ├─ stft.py          # unified STFT / ISTFT wrappers
│  ├─ metrics.py       # SI-SDR, STOI wrappers
│  └─ dataset.py       # PyTorch Dataset helpers
├─ results/


│  ├─ metrics/         # CSV result files
│  └─ demos/           # audio for listening tests
├─ requirements.txt
└─ README.md

## 5. How to run

### Create a virtual environment and install dependencies：

python -m venv .venv
.venv\Scripts\activate   # on Windows
pip install -r requirements.txt

### Generate reverberant data with real RIRs：

python -m scripts.generate_reverb

### Run classical frequency-domain baselines：

python -m scripts.run_baselines

### Train the Tiny-UNet model：

python -m scripts.train_tiny_unet

### Run Tiny-UNet on the test set

python -m scripts.run_tiny_unet

### Evaluate SI-SDR and STOI for all methods

python -m scripts.evaluate_methods

### Export demo samples

python -m scripts.export_demos
